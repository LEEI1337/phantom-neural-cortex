# ============================================================================
# PHANTOM NEURAL CORTEX - Environment Configuration
# Copy this file to .env and fill in your values
# ============================================================================

# ============================================================================
# LANGFUSE (LLM Observability) - REQUIRED
# ============================================================================
# Get your keys from: https://cloud.langfuse.com

LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key-here
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key-here
LANGFUSE_HOST=https://cloud.langfuse.com

# ============================================================================
# DATABASE
# ============================================================================

# SQLite (Development - Default)
DATABASE_URL=sqlite:///./lazy_bird.db

# PostgreSQL (Production)
# DATABASE_URL=postgresql://user:password@localhost:5432/lazy_bird

# ============================================================================
# REDIS (Session & Cache) - Optional but recommended
# ============================================================================

REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=

# ============================================================================
# API KEY ENCRYPTION - REQUIRED if storing API keys
# ============================================================================
# Generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"

FERNET_KEY=your-fernet-encryption-key-here

# ============================================================================
# CORS (for Frontend)
# ============================================================================

CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# ============================================================================
# LOGGING
# ============================================================================

LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# ============================================================================
# CONTEXT MANAGEMENT (NEW - Phase 1) â­
# ============================================================================
# Context window management configuration

# Default maximum tokens per model (override if needed)
CONTEXT_MAX_TOKENS=200000        # Default: Claude's limit
# CONTEXT_MAX_TOKENS=1000000     # For Gemini
# CONTEXT_MAX_TOKENS=128000      # For GPT-4

# Auto-pruning configuration
CONTEXT_PRUNE_THRESHOLD=0.8      # Auto-prune when context reaches 80%
CONTEXT_KEEP_RECENT=5            # Always keep last N messages
CONTEXT_PRUNE_MAX_AGE=30         # Remove messages older than N minutes

# Auto-compaction configuration  
CONTEXT_AUTO_COMPACT=true        # Enable automatic compaction
CONTEXT_COMPACT_THRESHOLD=0.7    # Compact when context reaches 70%
CONTEXT_COMPACT_MIN_SIZE=1000    # Only compact if context > N tokens

# Performance tuning
CONTEXT_CACHE_TOKEN_COUNTS=true  # Cache token counts (recommended)
CONTEXT_ASYNC_OPERATIONS=true   # Run pruning/compaction async
